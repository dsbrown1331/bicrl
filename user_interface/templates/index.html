<!DOCTYPE html>
<html>
<head>
    <title>Demonstration Sufficiency User Study</title>
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='styles.css') }}">
</head>
<body>
    <h1 align="center">Demonstration Sufficiency User Study</h1>
    <h2>Introduction</h2>
    <p>Welcome to the demonstration sufficiency user study. You will be teaching an AI agent how to navigate around an environment. You will be giving it demonstrations of what action to take in each cell, one demo at a time. After each demonstration, the agent will attempt to calculate whether or not it has received enough demonstrations in order to successfully complete the task. If it has, it will notify you and show you its learned policy, and you will be able to verify the policy yourself to see if it's satisfactory. Please keep in mind that the agent may take up to ~1 minute between demonstrations to calculate.</p>
    <h2>Configurations</h2>
    <p>There are two environment types: <strong>gridworld</strong> or <strong>driving</strong>.</p>
    <ul>
        <li><strong>Gridworld: </strong>In this environment, you want to help the agent accumulate as much reward as possible before reaching the goal. Each cell, or state, will be one of up to five colors/designs, representing five features: <strong>red</strong>, <strong>blue</strong>, <strong>green</strong>, <strong>purple</strong>, and <strong>star</strong>. The star state is the <strong>goal state</strong>, where you must try to get the agent to reach. It's also a terminal state, meaning that you can't move from it once you're in it, nor will you be allowed to give demonstrations for this state. There are four actions the agent can do in each non-terminal state: go <strong>(U)p</strong>, <strong>(D)own</strong>, <strong>(L)eft</strong>, or <strong>(R)ight</strong>. <p>You will also get to choose how many features your gridworld has: <strong>two</strong> (one color and the goal state), <strong>three</strong> (two colors and the goal state), <strong>four</strong> (three colors and the goal state), or <strong>five</strong> (four colors and the goal state).</p></li>
        <li><strong>Driving: </strong>In this environment, you want to help the agent navigate a stretch of road safely. <strong>Each lane is its own feature</strong>; other features are <strong>existing cars</strong> on the road and <strong>dirt patches</strong>. You must avoid collisions with other cars on the road as well as crashing into the dirt patches bordering the road. Consider this environment to be an infinite road; that is, moving from the top row will loop you back to the bottom row. There are three actions the agent can do in each state: move <strong>forward and (S)traight</strong>, <strong>forward and (L)eft</strong>, or <strong>forward and (R)ight</strong>.</li>
    </ul>
    <p>Every environment has an associated reward function, which is a mapping from each feature to a reward value; this is the reward you get if you land in a state with that feature. But wait, there's more! <strong>For gridworld, the discount factor is 0.95</strong>, meaning that every step you take, your possible rewards effectively decrease in absolute value by a factor of 0.05, so you should try to direct your agent to the goal.</p>
    <p>There are two <i>teaching</i> options: <strong>guided</strong> or <strong>freeform</strong>. In <strong>guided</strong>, you will be given a reward function as described above to guide your demonstrations. The reward function will let you know which states/features to avoid and thus what is the best path to the goal. In <strong>freeform</strong>, you will not be given a reward function. You will be able to decide for yourself how much each feature is worth, then give demonstrations based on this reward function. If you choose this option, we ask that you write down your reward function to keep your demonstrations consistent throughout the simulation. </p>
    <p>There are also two <i>demonstration selection</i> options: <strong>IID</strong> and <strong>active</strong>. In <strong>IID</strong>, at each iteration, you will get to give the agent a (state, action) demo pair in whichever order you prefer. You can even repeat demonstrations if you want! In <strong>active</strong>, the first demo is up to you, but subsequently the agent will request a state for you to give a demonstration. In this case, you MUST give the action corresponding with this state.</p>
    <h2>Instructions</h2>
    <p>It would be magnificent if you can run through (1) <i>at least one</i> simulation for each combination: {gridworld, driving} x {guided, freeform} x {IID, active}, and (2) <i>at least one</i> simulation for each of {2, 3, 4, 5} gridworld features (any other config ok). Thank you very much!</p>
    <!-- <p>Finally, there are five <i>thresholds</i> that you can choose for the agent: 0.1, 0.2, 0.3, 0.4, and 0.5. The <strong>lower</strong> the threshold, the <strong>more confident</strong> the agent must be before determining demonstration sufficiency.</p> -->

    <br>

    <div id="start-container" style="margin: 0 auto; text-align: center;">
        <p>Now, please select from the dropdown menus below and click Start to begin the simulation.</p>
        <label for="environment-option">Select Environment:</label>
        <select id="environment-option" name="environment_option">
            <option value="gridworld" selected>Gridworld</option>
            <option value="driving">Driving</option>
        </select>
        <br>
        <label for="features-option">(GRIDWORLD ONLY) Number of features:</label>
        <select id="features-option" name="features_option">
            <option value="2">2</option>
            <option value="3">3</option>
            <option value="4">4</option>
            <option value="5" selected>5</option>
        </select>
        <br>
        <label for="teaching-option">Teaching option:</label>
        <select id="teaching-option" name="teaching_option">
            <option value="guided" selected>Guided</option>
            <option value="freeform">Freeform</option>
        </select>
        <br>
        <label for="selection-option">Selection option:</label>
        <select id="selection-option" name="selection_option">
            <option value="iid" selected>IID</option>
            <option value="active">Active</option>
        </select>
        <br>
        <div style="display: none;">
            <label for="threshold-option">Threshold:</label>
            <select id="threshold-option" name="threshold_option">
                <option value="0.1" selected>0.1</option>
                <option value="0.2">0.2</option>
                <option value="0.3">0.3</option>
                <option value="0.4">0.4</option>
                <option value="0.5">0.5</option>
            </select>
        </div>
        <label for="reward-option">(FREEFORM ONLY) Your intended reward function, as comma-separated numbers. <i>If you chose gridworld</i> and e.g. 3 features, put 2 values for normal states, then 1 highest value for the goal (e.g. `0.2, 0.3, 0.5`). <i>If you chose driving</i>, put reward values in this order: left lane, middle lane, right lane, car collision, dirt patch crash:</label>
        <input type="text" id="reward-option" name="reward_option">
        <br>
        <form method="POST" action="/start" id="start-form">
            <button type="submit">Start</button>
        </form>
        <p id="user-options"></p>
    </div>
    
    <div id="grid-container" style="display: none;">
        <p id="reward-function" align="center">
            <span id="reward-function-vector"></span>
        </p>
        <div id="status-update"></div>
        <div class="grid">
            {% for i in range(grid_size) %}
                {% for j in range(grid_size) %}
                    <div class="square" id="{{ i * grid_size + j }}" style="background-color: {{ feature_color[grid[i][j]]}};">
                        {% if grid[i][j] == 5 %}
                            <div class="star">&#9733;</div>
                        {% endif %}
                        {% if grid[i * grid_size + j]['action'] %}
                            <div class="action">{{ grid[i * grid_size + j]['action'] }}</div>
                        {% endif %}
                    </div>
                {% endfor %}
            {% endfor %}
        </div>
        <div class="center-container">
            <button id="end-button" style="display: none;">End Simulation</button>
        </div>
    </div>  
    
    <script src="{{ url_for('static', filename='main.js') }}"></script>
</body>
</html>
